Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
(input_ids=None, attention_mask=None, labels=None, entity_pos=None, hts=None, list_feature_id=None, adj_mention=None, adj_syntactic_dependency_tree=None)
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
(input_ids=None, attention_mask=None, labels=None, entity_pos=None, hts=None, list_feature_id=None, adj_mention=None, adj_syntactic_dependency_tree=None)
hi (input_ids=None, attention_mask=None, labels=None, entity_pos=None, hts=None, list_feature_id=None, adj_mention=None, adj_syntactic_dependency_tree=None)
Model(
  (gc1): GraphConvolution (768 -> 256)
  (gc2): GraphConvolution (768 -> 128)
  (dropout): Dropout(p=0.5, inplace=False)
  (model): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31116, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (loss_fn): BSCELoss()
  (head_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (tail_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (bilinear): Linear(in_features=49152, out_features=2, bias=True)
  (bertdrop): Dropout(p=0.6, inplace=False)
  (liner): Linear(in_features=1024, out_features=3, bias=True)
  (segmentation_net): AttentionUNet(
    (inc): InConv(
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (down1): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (up1): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up2): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (outc): OutConv(
      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (adj_linear): Linear(in_features=512, out_features=256, bias=True)
)
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
(input_ids=None, attention_mask=None, labels=None, entity_pos=None, hts=None, list_feature_id=None, adj_mention=None, adj_syntactic_dependency_tree=None)
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
(input_ids=None, attention_mask=None, labels=None, entity_pos=None, hts=None, list_feature_id=None, adj_mention=None, adj_syntactic_dependency_tree=None)
hi (input_ids=None, attention_mask=None, labels=None, entity_pos=None, hts=None, list_feature_id=None, adj_mention=None, adj_syntactic_dependency_tree=None)
Model(
  (gc1): GraphConvolution (768 -> 256)
  (gc2): GraphConvolution (768 -> 128)
  (dropout): Dropout(p=0.5, inplace=False)
  (model): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31116, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (loss_fn): BSCELoss()
  (head_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (tail_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (bilinear): Linear(in_features=49152, out_features=2, bias=True)
  (bertdrop): Dropout(p=0.6, inplace=False)
  (liner): Linear(in_features=1024, out_features=3, bias=True)
  (segmentation_net): AttentionUNet(
    (inc): InConv(
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (down1): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (up1): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up2): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (outc): OutConv(
      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (adj_linear): Linear(in_features=512, out_features=256, bias=True)
)
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
(input_ids=None, attention_mask=None, labels=None, entity_pos=None, hts=None, list_feature_id=None, adj_mention=None, adj_syntactic_dependency_tree=None)
hi (input_ids=None, attention_mask=None, labels=None, entity_pos=None, hts=None, list_feature_id=None, adj_mention=None, adj_syntactic_dependency_tree=None)
Model(
  (gc1): GraphConvolution (768 -> 256)
  (gc2): GraphConvolution (768 -> 128)
  (dropout): Dropout(p=0.5, inplace=False)
  (model): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31116, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (loss_fn): BSCELoss()
  (head_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (tail_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (bilinear): Linear(in_features=49152, out_features=2, bias=True)
  (bertdrop): Dropout(p=0.6, inplace=False)
  (liner): Linear(in_features=1024, out_features=3, bias=True)
  (segmentation_net): AttentionUNet(
    (inc): InConv(
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (down1): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (up1): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up2): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (outc): OutConv(
      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (adj_linear): Linear(in_features=512, out_features=256, bias=True)
)
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Model(
  (gc1): GraphConvolution (768 -> 256)
  (gc2): GraphConvolution (768 -> 128)
  (dropout): Dropout(p=0.5, inplace=False)
  (model): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31116, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (loss_fn): BSCELoss()
  (head_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (tail_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (bilinear): Linear(in_features=49152, out_features=2, bias=True)
  (bertdrop): Dropout(p=0.6, inplace=False)
  (liner): Linear(in_features=1024, out_features=3, bias=True)
  (segmentation_net): AttentionUNet(
    (inc): InConv(
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (down1): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (up1): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up2): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (outc): OutConv(
      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (adj_linear): Linear(in_features=512, out_features=256, bias=True)
)
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Model(
  (gc1): GraphConvolution (768 -> 256)
  (gc2): GraphConvolution (768 -> 128)
  (dropout): Dropout(p=0.5, inplace=False)
  (model): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31116, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (loss_fn): BSCELoss()
  (head_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (tail_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (bilinear): Linear(in_features=49152, out_features=2, bias=True)
  (bertdrop): Dropout(p=0.6, inplace=False)
  (liner): Linear(in_features=1024, out_features=3, bias=True)
  (segmentation_net): AttentionUNet(
    (inc): InConv(
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (down1): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (up1): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up2): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (outc): OutConv(
      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (adj_linear): Linear(in_features=512, out_features=256, bias=True)
)
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Model(
  (gc1): GraphConvolution (768 -> 256)
  (gc2): GraphConvolution (768 -> 128)
  (dropout): Dropout(p=0.5, inplace=False)
  (model): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31116, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (loss_fn): BSCELoss()
  (head_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (tail_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (bilinear): Linear(in_features=49152, out_features=2, bias=True)
  (bertdrop): Dropout(p=0.6, inplace=False)
  (liner): Linear(in_features=1024, out_features=3, bias=True)
  (segmentation_net): AttentionUNet(
    (inc): InConv(
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (down1): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (up1): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up2): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (outc): OutConv(
      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (adj_linear): Linear(in_features=512, out_features=256, bias=True)
)
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Model(
  (gc1): GraphConvolution (768 -> 256)
  (gc2): GraphConvolution (768 -> 128)
  (dropout): Dropout(p=0.5, inplace=False)
  (model): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31116, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (loss_fn): BSCELoss()
  (head_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (tail_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (bilinear): Linear(in_features=49152, out_features=2, bias=True)
  (bertdrop): Dropout(p=0.6, inplace=False)
  (liner): Linear(in_features=1024, out_features=3, bias=True)
  (segmentation_net): AttentionUNet(
    (inc): InConv(
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (down1): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (up1): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up2): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (outc): OutConv(
      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (adj_linear): Linear(in_features=512, out_features=256, bias=True)
)
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Model(
  (gc1): GraphConvolution (768 -> 256)
  (gc2): GraphConvolution (768 -> 128)
  (dropout): Dropout(p=0.5, inplace=False)
  (model): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31116, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (loss_fn): BSCELoss()
  (head_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (tail_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (bilinear): Linear(in_features=49152, out_features=2, bias=True)
  (bertdrop): Dropout(p=0.6, inplace=False)
  (liner): Linear(in_features=1024, out_features=3, bias=True)
  (segmentation_net): AttentionUNet(
    (inc): InConv(
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (down1): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (up1): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up2): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (outc): OutConv(
      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (adj_linear): Linear(in_features=512, out_features=256, bias=True)
)
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
generate predict result in ./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Model(
  (gc1): GraphConvolution (768 -> 256)
  (gc2): GraphConvolution (768 -> 128)
  (dropout): Dropout(p=0.5, inplace=False)
  (model): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31116, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (loss_fn): BSCELoss()
  (head_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (tail_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (bilinear): Linear(in_features=49152, out_features=2, bias=True)
  (bertdrop): Dropout(p=0.6, inplace=False)
  (liner): Linear(in_features=1024, out_features=3, bias=True)
  (segmentation_net): AttentionUNet(
    (inc): InConv(
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (down1): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (up1): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up2): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (outc): OutConv(
      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (adj_linear): Linear(in_features=512, out_features=256, bias=True)
)
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
generate predict result in ./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
Model(
  (gc1): GraphConvolution (768 -> 256)
  (gc2): GraphConvolution (768 -> 128)
  (dropout): Dropout(p=0.5, inplace=False)
  (model): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31116, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (loss_fn): BSCELoss()
  (head_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (tail_extractor): Linear(in_features=1280, out_features=768, bias=True)
  (bilinear): Linear(in_features=49152, out_features=2, bias=True)
  (bertdrop): Dropout(p=0.6, inplace=False)
  (liner): Linear(in_features=1024, out_features=3, bias=True)
  (segmentation_net): AttentionUNet(
    (inc): InConv(
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (down1): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): DownLayer(
      (maxpool_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (up1): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up2): UpLayer(
      (up): Upsample(scale_factor=2.0, mode='bilinear')
      (conv): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (outc): OutConv(
      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (adj_linear): Linear(in_features=512, out_features=256, bias=True)
)
Namespace(task='cdr', data_dir='./dataset/cdr', transformer_type='bert', model_name_or_path='/Users/kavithakamarthy/Downloads/SSGU-CD/dataset/cdr/data/pretrained/scibert_scivocab_cased', train_file='train_filter.data', dev_file='dev_filter.data', test_file='test_filter.data', save_path='out/train_filter_bert_cdr_seed_BSCELoss_tree_0.3_0.5_66', load_path='', config_name='', tokenizer_name='', max_seq_length=1024, train_batch_size=12, test_batch_size=12, gradient_accumulation_steps=1, learning_rate=2e-05, adam_epsilon=1e-06, max_grad_norm=1.0, warmup_ratio=0.06, num_train_epochs=30, evaluation_steps=-1, seed=66, num_class=2, gnn='GCN', use_gcn='tree', dropout=0.5, loss='BSCELoss', s0=0.3, demo='false', unet_in_dim=3, unet_out_dim=256, down_dim=256, bert_lr=3e-05, max_height=64, rel2=0, save_result='', save_pubtator='./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66')
generate predict result in ./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66
./result/cdr/cdr_BSCELoss_tree_s0=0.3_dropout=0.5_66.pubtator
{'test_F1': 85.54464110238057, 'test_P': 90.21852143373027, 'test_R': 81.33208178862962}
